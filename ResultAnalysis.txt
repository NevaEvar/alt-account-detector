16.7.2025
Trained the model with short one off message pairs. The messages were vectorized and cosine was used to find features. 
Data was should've been fairly balanced for both true and false and the data set was fairly small.
TF + IDF in combination with random forest was used. (22.7.2025 correction/addition the properties of random forest weren't utilized until later date that will be stated in the notes.) 

Results:
              precision    recall  f1-score   support

           0       0.58      0.17      0.27       183
           1       0.53      0.88      0.66       195

    accuracy                           0.54       378
   macro avg       0.56      0.53      0.47       378
weighted avg       0.56      0.54      0.47       378

Improvements for the future:
Extract some other feature from the vectors to account for different features? 

Instead of training the model on small phrases add up messages from same user into bigger texts. Rational: Same user usually has common phrases that they use often. Thus it would stand to reason that including more text would bring these phrases more visible for the model.

Balance the data more. Rational: Recall on "Is message from the same user? yes." is very good while the opposite is very bad. 



17.7.2025
Checking balance of the data set revealed that the training data has more cases for True then False. Thus balanced the dataset better this time.
Trained the model with longer message pairs and extracted them from 3 raw text files meaning 3 times the training data compared to the first one.
Cosine and absolude difference were used this time for the vector features. (22.7.2025 correction absolute difference was not given a unique feature rather it was combined to cosine thus not utilizing the random forest at all)
As seen below there was a significant increase in both precision as well as accuracy.

Results:
              precision    recall  f1-score   support

           0       0.60      0.66      0.63        53
           1       0.62      0.57      0.59        53

    accuracy                           0.61       106
   macro avg       0.61      0.61      0.61       106
weighted avg       0.61      0.61      0.61       106

Improvements for the future:
Increasing the training data even more. Rational: Since the increase in training data raised both precision and recall it wouldn't hurt to increase it and see what happens.



18.7.2025
Trained with the same longer message pair set but doubled the amount of training data by extracting messages from 6 raw text files instead. 
Since there is a noticable decrease in percision and recall some form of overfitting might be happening.

Results:
              precision    recall  f1-score   support

           0       0.58      0.59      0.58       104
           1       0.58      0.57      0.57       104

    accuracy                           0.58       208
   macro avg       0.58      0.58      0.58       208
weighted avg       0.58      0.58      0.58       208

Improvements for the future:
Better feature engineering. Rational: There's still some wiggle room there.
Decreasing data set size. Rational: Reduces potential overfitting even if random forest is more resiliant to it.



22.7.2025
Realized a massive issue with the training data building process for False cases. Now fixed to actually contain opposing message pairs. This fix also increased the precision and recall significantly. Also removing the absolute difference feature contributed to the performance positively. 
Current model has 60 messages per row with an even 50/50 split for message1 and -2. 

Results:
              precision    recall  f1-score   support

           0       0.68      0.72      0.70       104
           1       0.70      0.66      0.68       104

    accuracy                           0.69       208
   macro avg       0.69      0.69      0.69       208
weighted avg       0.69      0.69      0.69       208

Improvements for the future:
Better feature engineering. Rational: Didn't improve it for the current version yet.
Increasing data set size. Rational: Increasing the data size only improved the perfomance on the current version. Testing further wouldn't hurt.



30.7.2025
Added more features including punctuation frequency and average word length. The model now is working with 3 features and the performance is significantly improved yet again. The training data size is the same as before but will be later increased to test if there're more gains to make there.
Additional improvements are that the model is more balansed on precision and recall for both true and false cases. 

Results: 
              precision    recall  f1-score   support

           0       0.80      0.79      0.79       104
           1       0.79      0.80      0.79       104

    accuracy                           0.79       208
   macro avg       0.79      0.79      0.79       208
weighted avg       0.79      0.79      0.79       208


Improvements for the future: 
Increasing data set size. Rational: discussed above in previouse update.
Adding more features. Rational: same as before.
More comprehensive testing. Rational: To make sure that the model is actually performing as well as the results are showing. 

